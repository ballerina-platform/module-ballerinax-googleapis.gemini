// AUTO-GENERATED FILE. DO NOT MODIFY.
// This file is auto-generated by the Ballerina OpenAPI tool.

import ballerina/http;

# The Gemini API allows developers to build generative AI applications using Gemini models. Gemini is our most capable model, built from the ground up to be multimodal. It can generalize and seamlessly understand, operate across, and combine different types of information including language, images, audio, video, and code. You can use the Gemini API for use cases like reasoning across text and images, content generation, dialogue agents, summarization and classification systems, and more.
public isolated client class Client {
    final http:Client clientEp;
    # Gets invoked to initialize the `connector`.
    #
    # + config - The configurations to be used when initializing the `connector` 
    # + serviceUrl - URL of the target service 
    # + return - An error if connector initialization failed 
    public isolated function init(ConnectionConfig config, string serviceUrl = "https://generativelanguage.googleapis.com/") returns error? {
        http:ClientConfiguration httpClientConfig = {auth: config.auth, httpVersion: config.httpVersion, timeout: config.timeout, forwarded: config.forwarded, poolConfig: config.poolConfig, compression: config.compression, circuitBreaker: config.circuitBreaker, retryConfig: config.retryConfig, validation: config.validation};
        do {
            if config.http1Settings is ClientHttp1Settings {
                ClientHttp1Settings settings = check config.http1Settings.ensureType(ClientHttp1Settings);
                httpClientConfig.http1Settings = {...settings};
            }
            if config.http2Settings is http:ClientHttp2Settings {
                httpClientConfig.http2Settings = check config.http2Settings.ensureType(http:ClientHttp2Settings);
            }
            if config.cache is http:CacheConfig {
                httpClientConfig.cache = check config.cache.ensureType(http:CacheConfig);
            }
            if config.responseLimits is http:ResponseLimitConfigs {
                httpClientConfig.responseLimits = check config.responseLimits.ensureType(http:ResponseLimitConfigs);
            }
            if config.secureSocket is http:ClientSecureSocket {
                httpClientConfig.secureSocket = check config.secureSocket.ensureType(http:ClientSecureSocket);
            }
            if config.proxy is http:ProxyConfig {
                httpClientConfig.proxy = check config.proxy.ensureType(http:ProxyConfig);
            }
        }
        http:Client httpEp = check new (serviceUrl, httpClientConfig);
        self.clientEp = httpEp;
        return;
    }

    # Generates multiple embedding vectors from the input `Content` which consists of a batch of strings represented as `EmbedContentRequest` objects.
    #
    # + model - Required. The model's resource name. This serves as an ID for the Model to use. This name should match a model name returned by the `ListModels` method. Format: `models/{model}`
    # + payload - The batch of `Content` to embed
    # + headers - Headers to be sent with the request 
    # + queries - Queries to be sent with the request 
    # + return - Successful response 
    remote isolated function generativelanguage\.models\.batchEmbedContents(string model, BatchEmbedContentsRequest payload, map<string|string[]> headers = {}, *GenerativelanguageModelsBatchembedcontentsQueries queries) returns http:Response|error {
        string resourcePath = string `/v1/${getEncodedUri(model)}:batchEmbedContents`;
        resourcePath = resourcePath + check getPathForQueryParam(queries);
        http:Request request = new;
        json jsonBody = payload.toJson();
        request.setPayload(jsonBody, "application/json");
        return self.clientEp->post(resourcePath, request, headers);
    }

    # Runs a model's tokenizer on input `Content` and returns the token count. Refer to the [tokens guide](https://ai.google.dev/gemini-api/docs/tokens) to learn more about tokens.
    #
    # + model - Required. The model's resource name. This serves as an ID for the Model to use. This name should match a model name returned by the `ListModels` method. Format: `models/{model}`
    # + payload - The `Content` to tokenize
    # + headers - Headers to be sent with the request 
    # + queries - Queries to be sent with the request 
    # + return - Successful response 
    remote isolated function generativelanguage\.models\.countTokens(string model, CountTokensRequest payload, map<string|string[]> headers = {}, *GenerativelanguageModelsCounttokensQueries queries) returns http:Response|error {
        string resourcePath = string `/v1/${getEncodedUri(model)}:countTokens`;
        resourcePath = resourcePath + check getPathForQueryParam(queries);
        http:Request request = new;
        json jsonBody = payload.toJson();
        request.setPayload(jsonBody, "application/json");
        return self.clientEp->post(resourcePath, request, headers);
    }

    # Generates a text embedding vector from the input `Content` using the specified [Gemini Embedding model](https://ai.google.dev/gemini-api/docs/models/gemini#text-embedding).
    #
    # + model - Required. The model's resource name. This serves as an ID for the Model to use. This name should match a model name returned by the `ListModels` method. Format: `models/{model}`
    # + payload - The `Content` to embed
    # + headers - Headers to be sent with the request 
    # + queries - Queries to be sent with the request 
    # + return - Successful response 
    remote isolated function generativelanguage\.models\.embedContent(string model, EmbedContentRequest payload, map<string|string[]> headers = {}, *GenerativelanguageModelsEmbedcontentQueries queries) returns http:Response|error {
        string resourcePath = string `/v1/${getEncodedUri(model)}:embedContent`;
        resourcePath = resourcePath + check getPathForQueryParam(queries);
        http:Request request = new;
        json jsonBody = payload.toJson();
        request.setPayload(jsonBody, "application/json");
        return self.clientEp->post(resourcePath, request, headers);
    }

    # Generates a model response given an input `GenerateContentRequest`. Refer to the [text generation guide](https://ai.google.dev/gemini-api/docs/text-generation) for detailed usage information. Input capabilities differ between models, including tuned models. Refer to the [model guide](https://ai.google.dev/gemini-api/docs/models/gemini) and [tuning guide](https://ai.google.dev/gemini-api/docs/model-tuning) for details.
    #
    # + model - Required. The name of the `Model` to use for generating the completion. Format: `models/{model}`.
    # + payload - The `GenerateContentRequest` to generate content
    # + headers - Headers to be sent with the request 
    # + queries - Queries to be sent with the request 
    # + return - Successful response 
    remote isolated function generativelanguage\.models\.generateContent(string model, GenerateContentRequest payload, map<string|string[]> headers = {}, *GenerativelanguageModelsGeneratecontentQueries queries) returns http:Response|error {
        string resourcePath = string `/v1/${getEncodedUri(model)}:generateContent`;
        resourcePath = resourcePath + check getPathForQueryParam(queries);
        http:Request request = new;
        json jsonBody = payload.toJson();
        request.setPayload(jsonBody, "application/json");
        return self.clientEp->post(resourcePath, request, headers);
    }

    # Lists the [`Model`s](https://ai.google.dev/gemini-api/docs/models/gemini) available through the Gemini API.
    #
    # + headers - Headers to be sent with the request 
    # + queries - Queries to be sent with the request 
    # + return - Successful response 
    remote isolated function generativelanguage\.models\.list(map<string|string[]> headers = {}, *GenerativelanguageModelsListQueries queries) returns http:Response|error {
        string resourcePath = string `/v1/models`;
        resourcePath = resourcePath + check getPathForQueryParam(queries);
        return self.clientEp->get(resourcePath, headers);
    }

    # Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service.
    #
    # + name - The name of the operation resource.
    # + headers - Headers to be sent with the request 
    # + queries - Queries to be sent with the request 
    # + return - Successful response 
    remote isolated function generativelanguage\.models\.operations\.get(string name, map<string|string[]> headers = {}, *GenerativelanguageModelsOperationsGetQueries queries) returns http:Response|error {
        string resourcePath = string `/v1/${getEncodedUri(name)}`;
        resourcePath = resourcePath + check getPathForQueryParam(queries);
        return self.clientEp->get(resourcePath, headers);
    }

    # Lists operations that match the specified filter in the request. If the server doesn't support this method, it returns `UNIMPLEMENTED`.
    #
    # + name - The name of the operation's parent resource.
    # + headers - Headers to be sent with the request 
    # + queries - Queries to be sent with the request 
    # + return - Successful response 
    remote isolated function generativelanguage\.models\.operations\.list(string name, map<string|string[]> headers = {}, *GenerativelanguageModelsOperationsListQueries queries) returns http:Response|error {
        string resourcePath = string `/v1/${getEncodedUri(name)}/operations`;
        resourcePath = resourcePath + check getPathForQueryParam(queries);
        return self.clientEp->get(resourcePath, headers);
    }

    # Generates a [streamed response](https://ai.google.dev/gemini-api/docs/text-generation?lang=python#generate-a-text-stream) from the model given an input `GenerateContentRequest`.
    #
    # + model - Required. The name of the `Model` to use for generating the completion. Format: `models/{model}`.
    # + payload - The `GenerateContentRequest` to generate content
    # + headers - Headers to be sent with the request 
    # + queries - Queries to be sent with the request 
    # + return - Successful response 
    remote isolated function generativelanguage\.models\.streamGenerateContent(string model, GenerateContentRequest payload, map<string|string[]> headers = {}, *GenerativelanguageModelsStreamgeneratecontentQueries queries) returns http:Response|error {
        string resourcePath = string `/v1/${getEncodedUri(model)}:streamGenerateContent`;
        resourcePath = resourcePath + check getPathForQueryParam(queries);
        http:Request request = new;
        json jsonBody = payload.toJson();
        request.setPayload(jsonBody, "application/json");
        return self.clientEp->post(resourcePath, request, headers);
    }

    # Deletes a long-running operation. This method indicates that the client is no longer interested in the operation result. It does not cancel the operation. If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`.
    #
    # + name - The name of the operation resource to be deleted.
    # + headers - Headers to be sent with the request 
    # + queries - Queries to be sent with the request 
    # + return - Successful response 
    remote isolated function generativelanguage\.operations\.delete(string name, map<string|string[]> headers = {}, *GenerativelanguageOperationsDeleteQueries queries) returns http:Response|error {
        string resourcePath = string `/v1/${getEncodedUri(name)}`;
        resourcePath = resourcePath + check getPathForQueryParam(queries);
        return self.clientEp->delete(resourcePath, headers = headers);
    }

    # Starts asynchronous cancellation on a long-running operation. The server makes a best effort to cancel the operation, but success is not guaranteed. If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`. Clients can use Operations.GetOperation or other methods to check whether the cancellation succeeded or whether the operation completed despite cancellation. On successful cancellation, the operation is not deleted; instead, it becomes an operation with an Operation.error value with a google.rpc.Status.code of `1`, corresponding to `Code.CANCELLED`.
    #
    # + name - The name of the operation resource to be cancelled.
    # + payload - The request to cancel the operation    
    # + headers - Headers to be sent with the request 
    # + queries - Queries to be sent with the request 
    # + return - Successful response 
    remote isolated function generativelanguage\.tunedModels\.operations\.cancel(string name, CancelOperationRequest payload, map<string|string[]> headers = {}, *GenerativelanguageTunedmodelsOperationsCancelQueries queries) returns http:Response|error {
        string resourcePath = string `/v1/${getEncodedUri(name)}:cancel`;
        resourcePath = resourcePath + check getPathForQueryParam(queries);
        http:Request request = new;
        json jsonBody = payload.toJson();
        request.setPayload(jsonBody, "application/json");
        return self.clientEp->post(resourcePath, request, headers);
    }
}
